{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b08fd6",
   "metadata": {},
   "source": [
    "## Coding a single neuron\n",
    "\n",
    "Let's imagine we have a single neuron, and three inputs.  \n",
    "Each input needs a weight associated with it. These weights are the one of the types of values that change inside the model at training time, along with biases. For now we will make up the weights.  \n",
    "Similarly, we need a bias. Since we are modeling a single neuron, we will have only one bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d663a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1,2,3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872d4caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "output = (\n",
    "    inputs[0]*weights[0] +\n",
    "    inputs[1]*weights[1] +\n",
    "    inputs[2]*weights[2] +\n",
    "    bias\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb538af",
   "metadata": {},
   "source": [
    "## A layer of neurons\n",
    "\n",
    "A group of neurons is defined as a layer. Each neuron takes the same input, but has its own set of weights and biases, thus producing its own output. Each layers has one output for each neuron.  \n",
    "In this example we will have a three-neurons layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb26be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.8, 1.01, 2.3549999999999995]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1,2,3,2.5]\n",
    "#defining weights\n",
    "w1 = [0.2, 0.8, 0.5, 1]\n",
    "w2 = [0.3, -0.91, 0.26, -0.5]\n",
    "w3 = [-0.26, -0.27, 0.16, 0.87]\n",
    "#defining biases\n",
    "b1 = 2\n",
    "b2 = 3\n",
    "b3 = 0.5\n",
    "\n",
    "outputs = [\n",
    "    inputs[0]*w1[0] + inputs[1]*w1[1] + inputs[2]*w1[2] + inputs[3]*w1[3] +b1, \n",
    "    inputs[0]*w2[0] + inputs[1]*w2[1] + inputs[2]*w2[2] + inputs[3]*w2[3] +b2, \n",
    "    inputs[0]*w3[0] + inputs[1]*w3[1] + inputs[2]*w3[2] + inputs[3]*w3[3] +b3, \n",
    "]\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8174a",
   "metadata": {},
   "source": [
    "Let's scale the code up so it can handle multiple **fully connected layers**, i.e. layers that where every neuron in l1 is connected to every layer in l2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5379ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.8, 1.01, 2.3549999999999995]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1,2,3,2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, 0.5, 1],\n",
    "    [0.3, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.16, 0.87]\n",
    "]\n",
    "biases = [2,3,0.5]\n",
    "\n",
    "layer_output = []\n",
    "\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    output = 0\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        output += n_input * weight\n",
    "    output += neuron_bias\n",
    "    layer_output.append(output)\n",
    "\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee87a42",
   "metadata": {},
   "source": [
    "## Tensors, arrays and vectors\n",
    "\n",
    "To understand tensors, let's first describe other data structures in Python. Let's start with a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978e499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,5,6]\n",
    "lol = [[1,2,5,6],\n",
    "      [3,2,13]]\n",
    "l2 = [\n",
    "    [1,2,3],\n",
    "    [5,6]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcd511",
   "metadata": {},
   "source": [
    "Lists can be not **homologous**, which means that specific lists are not arrays (the previous one is one such list). A list is homologous if each list along a dimension is identically long.  \n",
    "A rectangular array (homologous list) can also be called a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99bc0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [[4,2],\n",
    "    [2,3],\n",
    "    [5,6]]\n",
    "#m has shape (3,2)\n",
    "#3 elements in the first dimension (i.e., the number of sublists it contains)\n",
    "#2 elements in the second dimension (i.e., the number of elements present in each sublists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165abb70",
   "metadata": {},
   "source": [
    "In the context of deep learning, a *tensor object is an object that can be represented as an array*. While they are *more* than just arrays, in programming we represent them through arrays, hence the confusion.  \n",
    "Similarly, a *vector* is identified as a 1-dimensional array in Numpy / a list in basic Python. This is in contrast with the physics notion of vector, where it has magnitude and direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03e32f",
   "metadata": {},
   "source": [
    "## Dot Product and Vector Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90254c",
   "metadata": {},
   "source": [
    "One of the most important operations on vectors is vector multiplication. When we multiply vectors, we either do dot product or corss product.  \n",
    "- A **cross product** results in a vector  \n",
    "- A **dot product** result in a scalar  \n",
    "\n",
    "A **dot product** is calculated as the sum of products of consectuve vector elements, where vectors have to be of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd1c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7506ac",
   "metadata": {},
   "source": [
    "This is exactly the ooperation that we have used previously in the neuron!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95e134",
   "metadata": {},
   "source": [
    "## A single neuron using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dcbb90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186defda",
   "metadata": {},
   "source": [
    "## A layer of neurons using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b5441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.8   1.01  2.355]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1,2,3,2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, 0.5, 1],\n",
    "    [0.3, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.16, 0.87]\n",
    "]\n",
    "biases = [2,3,0.5]\n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96144128",
   "metadata": {},
   "source": [
    "Neural Networks tend to receive data in batches. So far the inputs havebeen made up of one sample (or observation) of various features. Often neural networks expect to take in many samples at a time for two reasions:\n",
    "- it's faster to train in batches in parallel processing\n",
    "- batches help with generalization during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf78d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 9 8 5]\n",
      " [1 9 6 5]\n",
      " [8 5 2 3]\n",
      " [9 6 3 0]\n",
      " [2 0 1 7]\n",
      " [4 7 2 0]\n",
      " [6 7 4 1]\n",
      " [9 9 5 9]]\n"
     ]
    }
   ],
   "source": [
    "batch = np.random.randint(10, size=(8,4))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a995f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
